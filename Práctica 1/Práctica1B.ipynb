{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f50654f",
   "metadata": {},
   "source": [
    "# Parte B: Evaluación de modelos de AA"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2d1f36a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:04.810223Z",
     "start_time": "2025-02-26T16:09:04.614397Z"
    }
   },
   "source": [
    "  \n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, NMF\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5f4f5d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:05.300292Z",
     "start_time": "2025-02-26T16:09:05.295533Z"
    }
   },
   "source": [
    "# Definir SEED\n",
    "SEED = 42"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1\n",
   "id": "2dac70a163545935"
  },
  {
   "cell_type": "code",
   "id": "5027cc5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:06.212397Z",
     "start_time": "2025-02-26T16:09:06.076200Z"
    }
   },
   "source": [
    "# Cargar el dataset de MovieLens de 100K\n",
    "data = Dataset.load_builtin('ml-100k')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2",
   "id": "64d6d1f28370ca91"
  },
  {
   "cell_type": "code",
   "id": "8d28d446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:07.439957Z",
     "start_time": "2025-02-26T16:09:07.348880Z"
    }
   },
   "source": [
    "# Dividir el dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=SEED)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3",
   "id": "e5bc089d553381f9"
  },
  {
   "cell_type": "code",
   "id": "0337809e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:08.884740Z",
     "start_time": "2025-02-26T16:09:08.880443Z"
    }
   },
   "source": [
    "# Evaluar distintos algoritmos de recomendación\n",
    "# Filtrado colaborativo basado en vecinos (KNNBasic)\n",
    "algo_knn_user = KNNBasic(sim_options={'name': 'pearson', 'user_based': True}, random_state=SEED)\n",
    "algo_knn_item = KNNBasic(sim_options={'name': 'pearson', 'user_based': False}, random_state=SEED)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "57c41a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:11.776020Z",
     "start_time": "2025-02-26T16:09:11.772277Z"
    }
   },
   "source": [
    "# Filtrado colaborativo basado en modelos (SVD y NMF)\n",
    "algo_svd = SVD(random_state=SEED)\n",
    "algo_nmf = NMF(random_state=SEED)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 y 5",
   "id": "ab8a234454ead779"
  },
  {
   "cell_type": "code",
   "id": "c82b1208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:12.646816Z",
     "start_time": "2025-02-26T16:09:12.642198Z"
    }
   },
   "source": [
    "# Entrenar y evaluar los algoritmos\n",
    "algorithms = [(\"KNN-User-Based\", algo_knn_user),\n",
    "              (\"KNN-Item-Based\", algo_knn_item),\n",
    "              (\"SVD\", algo_svd),\n",
    "              (\"NMF\", algo_nmf)]\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "c4859cf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:23.313650Z",
     "start_time": "2025-02-26T16:09:13.560251Z"
    }
   },
   "source": [
    "# Mostrar resultados de 5 predicciones para cada algoritmo\n",
    "for name, algo in algorithms:\n",
    "    print(f\"Evaluando {name}...\")\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    print(f\"{name} RMSE: {rmse}\")\n",
    "\n",
    "    print(\"Algunas predicciones:\")\n",
    "    for pred in predictions[:5]:\n",
    "        print(pred)\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando KNN-User-Based...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0182\n",
      "KNN-User-Based RMSE: 1.018246371164168\n",
      "Algunas predicciones:\n",
      "user: 391        item: 591        r_ui = 4.00   est = 3.69   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 181        item: 1291       r_ui = 1.00   est = 3.08   {'actual_k': 6, 'was_impossible': False}\n",
      "user: 637        item: 268        r_ui = 2.00   est = 3.58   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 332        item: 451        r_ui = 5.00   est = 3.17   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 271        item: 204        r_ui = 4.00   est = 3.82   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "Evaluando KNN-Item-Based...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0465\n",
      "KNN-Item-Based RMSE: 1.046509372244098\n",
      "Algunas predicciones:\n",
      "user: 391        item: 591        r_ui = 4.00   est = 3.72   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 181        item: 1291       r_ui = 1.00   est = 1.51   {'actual_k': 25, 'was_impossible': False}\n",
      "user: 637        item: 268        r_ui = 2.00   est = 2.24   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 332        item: 451        r_ui = 5.00   est = 4.08   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 271        item: 204        r_ui = 4.00   est = 3.34   {'actual_k': 40, 'was_impossible': False}\n",
      "\n",
      "Evaluando SVD...\n",
      "RMSE: 0.9396\n",
      "SVD RMSE: 0.9395567173787085\n",
      "Algunas predicciones:\n",
      "user: 391        item: 591        r_ui = 4.00   est = 3.56   {'was_impossible': False}\n",
      "user: 181        item: 1291       r_ui = 1.00   est = 1.52   {'was_impossible': False}\n",
      "user: 637        item: 268        r_ui = 2.00   est = 3.02   {'was_impossible': False}\n",
      "user: 332        item: 451        r_ui = 5.00   est = 4.07   {'was_impossible': False}\n",
      "user: 271        item: 204        r_ui = 4.00   est = 3.86   {'was_impossible': False}\n",
      "\n",
      "Evaluando NMF...\n",
      "RMSE: 0.9650\n",
      "NMF RMSE: 0.9650334729963461\n",
      "Algunas predicciones:\n",
      "user: 391        item: 591        r_ui = 4.00   est = 3.70   {'was_impossible': False}\n",
      "user: 181        item: 1291       r_ui = 1.00   est = 1.50   {'was_impossible': False}\n",
      "user: 637        item: 268        r_ui = 2.00   est = 2.89   {'was_impossible': False}\n",
      "user: 332        item: 451        r_ui = 5.00   est = 4.22   {'was_impossible': False}\n",
      "user: 271        item: 204        r_ui = 4.00   est = 3.87   {'was_impossible': False}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fijándonos solo en el usuario 391 el cual valoro la película con un 4.0, el modelo KNN-User estimo que valoraría la película xon un 3.69, el modelo KNN-Item estimo una puntuacion de 3.72, el modelo SVD estimo una puntuación de 3.52 y el modelo NMF estimo una puntuación de 3.7\n",
    "## SOLO ESTABA COMPARANDO LAS ESTIMACIONES A UN USUARIO CONCRETO ASI QUE CUANDO ANALICEMOS LOS DATOS AL COMPLETO SACAREMOS CONCLUSIONES"
   ],
   "id": "222a985df4a34010"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6",
   "id": "e918011167d33bff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creamos una función para obtener las metricas Precision@10, Recall@10 y NDCG@10",
   "id": "21ab1930d5a1f451"
  },
  {
   "cell_type": "code",
   "id": "883fb61f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:46.468346Z",
     "start_time": "2025-02-26T16:09:46.463811Z"
    }
   },
   "source": [
    "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
    "import numpy as np\n",
    "def evaluate_metrics(predictions, k=10):\n",
    "    # Convertir predicciones a un formato manejable\n",
    "    relevant_items = []\n",
    "    recommended_items = []\n",
    "    scores = []\n",
    "\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        relevant_items.append(1 if true_r > 4 else 0)  # 1: relevante, 0: no relevante\n",
    "        scores.append(est)\n",
    "\n",
    "    # Obtener índices de las top-k recomendaciones\n",
    "    sorted_indices = np.argsort(scores)[::-1][:k]\n",
    "    recommended_items = [1 if i in sorted_indices else 0 for i in range(len(scores))]\n",
    "\n",
    "    # Calcular Precision@k, Recall@k, NDCG@k\n",
    "    precision = precision_score(relevant_items, recommended_items, zero_division=1)\n",
    "    recall = recall_score(relevant_items, recommended_items, zero_division=1)\n",
    "    ndcg = ndcg_score([relevant_items], [scores], k=k)\n",
    "\n",
    "    return precision, recall, ndcg"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "evaluamos cada algoritmo",
   "id": "cfa7fb9ad2bfdf6d"
  },
  {
   "cell_type": "code",
   "id": "b7f56813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T16:09:52.699849Z",
     "start_time": "2025-02-26T16:09:48.869410Z"
    }
   },
   "source": [
    "# Evaluar cada algoritmo\n",
    "results = []\n",
    "for name, algo in algorithms:\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    precision, recall, ndcg = evaluate_metrics(predictions, k=10)\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Precision@10\": precision,\n",
    "        \"Recall@10\": recall,\n",
    "        \"NDCG@10\": ndcg\n",
    "    })\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25000, 0]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m algo\u001B[38;5;241m.\u001B[39mtest(testset)\n\u001B[0;32m      6\u001B[0m     rmse \u001B[38;5;241m=\u001B[39m accuracy\u001B[38;5;241m.\u001B[39mrmse(predictions, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m----> 7\u001B[0m     precision, recall, ndcg \u001B[38;5;241m=\u001B[39m evaluate_metrics(predictions, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      9\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[0;32m     10\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModelo\u001B[39m\u001B[38;5;124m\"\u001B[39m: name,\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRMSE\u001B[39m\u001B[38;5;124m\"\u001B[39m: rmse,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNDCG@10\u001B[39m\u001B[38;5;124m\"\u001B[39m: ndcg\n\u001B[0;32m     15\u001B[0m     })\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[18], line 18\u001B[0m, in \u001B[0;36mevaluate_metrics\u001B[1;34m(predictions, k)\u001B[0m\n\u001B[0;32m     11\u001B[0m      scores\u001B[38;5;241m.\u001B[39mappend(est)\n\u001B[0;32m     13\u001B[0m  \u001B[38;5;66;03m# Obtener índices de las top-k recomendaciones\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# sorted_indices = np.argsort(scores)[::-1][:k]\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# recommended_items = [1 if i in sorted_indices else 0 for i in range(len(scores))]\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m  \u001B[38;5;66;03m# Calcular Precision@k, Recall@k, NDCG@k\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m  precision \u001B[38;5;241m=\u001B[39m precision_score(relevant_items, recommended_items, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     19\u001B[0m  recall \u001B[38;5;241m=\u001B[39m recall_score(relevant_items, recommended_items, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     20\u001B[0m  ndcg \u001B[38;5;241m=\u001B[39m ndcg_score([relevant_items], [scores], k\u001B[38;5;241m=\u001B[39mk)\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2204\u001B[0m, in \u001B[0;36mprecision_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   2037\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   2038\u001B[0m     {\n\u001B[0;32m   2039\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2064\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2065\u001B[0m ):\n\u001B[0;32m   2066\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[0;32m   2067\u001B[0m \n\u001B[0;32m   2068\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2202\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2204\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m precision_recall_fscore_support(\n\u001B[0;32m   2205\u001B[0m         y_true,\n\u001B[0;32m   2206\u001B[0m         y_pred,\n\u001B[0;32m   2207\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[0;32m   2208\u001B[0m         pos_label\u001B[38;5;241m=\u001B[39mpos_label,\n\u001B[0;32m   2209\u001B[0m         average\u001B[38;5;241m=\u001B[39maverage,\n\u001B[0;32m   2210\u001B[0m         warn_for\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m,),\n\u001B[0;32m   2211\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m   2212\u001B[0m         zero_division\u001B[38;5;241m=\u001B[39mzero_division,\n\u001B[0;32m   2213\u001B[0m     )\n\u001B[0;32m   2214\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1789\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1626\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[0;32m   1627\u001B[0m \n\u001B[0;32m   1628\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1786\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1788\u001B[0m _check_zero_division(zero_division)\n\u001B[1;32m-> 1789\u001B[0m labels \u001B[38;5;241m=\u001B[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1792\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1561\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1561\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1564\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \n\u001B[0;32m     78\u001B[0m \u001B[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03my_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    102\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(y_true, y_pred)\n\u001B[1;32m--> 103\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[0;32m    104\u001B[0m type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    105\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [25000, 0]"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d2061cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T10:38:29.804029Z",
     "start_time": "2025-02-26T10:38:29.799854Z"
    }
   },
   "source": [
    "# Crear un DataFrame a partir de los resultados\n",
    "results_df = pd.DataFrame(results)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "c4a69f667f5f8ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T10:38:31.035774Z",
     "start_time": "2025-02-26T10:38:31.028130Z"
    }
   },
   "source": [
    "# Mostrar la tabla\n",
    "print(results_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Modelo      RMSE  Precision@10  Recall@10   NDCG@10\n",
      "0  KNN-User-Based  1.018246           0.7   0.001324  0.571429\n",
      "1  KNN-Item-Based  1.046509           0.5   0.000946  0.538462\n",
      "2             SVD  0.939557           0.8   0.001513  0.794521\n",
      "3             NMF  0.965033           0.6   0.001135  0.686275\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "eac565d9484b43e8",
   "metadata": {},
   "source": [
    "# Conclusiones:\n",
    "- **RMSE**: El modelo **SVD** tiene el menor error (RMSE más bajo), lo que indica que realiza predicciones más cercanas a las calificaciones reales.\n",
    "- **Precision@10**: El modelo **SVD** proporciona la mayor precisión, es decir, recomienda un mayor número de películas relevantes entre las top-10.\n",
    "- **Recall@10**: **SVD** también tiene el mejor desempeño al recuperar un mayor porcentaje de películas relevantes.\n",
    "- **NDCG@10**: **SVD** cuenta con el mayor valor de NDCG, lo que indica una mejor organización de recomendaciones relevantes en posiciones altas de la lista.\n",
    "\n",
    "El modelo **SVD** es el mejor entre los evaluados porque:\n",
    "1. Tiene el menor RMSE, lo que confirma la calidad de sus predicciones.\n",
    "2. Sobresale en las métricas de Precision@10, Recall@10 y NDCG@10, demostrando que ofrece películas relevantes y bien ordenadas dentro de las top-10"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
